{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "human_names_vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfALxPRVOmolmTBqI/gHAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ladvien/gan_name_maker/blob/master/human_names_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksp84kLQXGc2",
        "colab_type": "text"
      },
      "source": [
        "The intent is to create a Variational Autoencoder which can take one-hot encoded human first names and encode them into a latent space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USOBfNI5aT2W",
        "colab_type": "text"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQZ5V2jJXB8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Engineering parameters.\n",
        "data_set            = '93k' # \"6k\" or \"93\n",
        "pad_character       = '~'\n",
        "allowed_chars       = f'abcdefghijklmnopqrstuvwxyz{pad_character}'\n",
        "len_allow_chars     = len(allowed_chars)\n",
        "max_name_length     = 10 \n",
        "\n",
        "# Inputs\n",
        "inputs              = len_allow_chars * max_name_length\n",
        "\n",
        "# Parameters\n",
        "optimizer_name        = 'rmsprop'\n",
        "learning_rate         = 0.0001\n",
        "\n",
        "epochs                = 45000\n",
        "batch_size            = 32\n",
        "num_samples           = 8\n",
        "\n",
        "e_dropout             = 0.2\n",
        "d_dropout             = 0.2\n",
        "\n",
        "e_h_activation          = 'relu' # Activation function for hidden layers.\n",
        "d_h_activation          = 'relu'\n",
        "\n",
        "activation              = 'sigmoid' \n",
        "\n",
        "e_batchnorm             = False\n",
        "d_batchnorm             = False\n",
        "\n",
        "params = {\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'optimizer_name': optimizer_name,\n",
        "    'inputs': inputs,\n",
        "    'num_samples_per_step': num_samples,\n",
        "    'allowed_chars': allowed_chars,\n",
        "    'max_name_length': max_name_length,\n",
        "    'e_h_activation': e_h_activation,\n",
        "    'd_h_activation': d_h_activation,\n",
        "    'e_dropout': e_dropout,\n",
        "    'd_dropout': d_dropout,\n",
        "    'e_batchnorm': e_batchnorm,\n",
        "    'd_batchnorm': d_batchnorm\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQDJ5ddvaeaN",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSEteMLRac8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROoRaZoaiJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12035387-b8a0-4151-fa3b-d9a5a72b1b4e"
      },
      "source": [
        "!git clone https://github.com/Ladvien/gan_name_maker"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gan_name_maker' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QyZEToiajVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if data_set == '6k':\n",
        "  # ~6k names\n",
        "  df = pd.read_csv('./gan_name_maker/vectorized_names_6k.csv')\n",
        "elif data_set == '93k':\n",
        "  # ~93k names\n",
        "  df = pd.read_csv('./gan_name_maker/vectorized_names_93k.csv')\n",
        "  df = df.rename(columns = {'Name':'name'})\n",
        "else:\n",
        "  print('Please select data_set')\n",
        "\n",
        "params['data_set'] = data_set\n",
        "\n",
        "cols = list(df)\n",
        "\n",
        "# Move the name column to the beginning.\n",
        "cols.insert(0, cols.pop(cols.index('name')))\n",
        "df = df.loc[:, cols]\n",
        "\n",
        "# Drop the yucky columns.\n",
        "df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "# Sort values by name\n",
        "df.sort_values(by = 'name', ascending = True, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWy-Mvagas2j",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw99U-mRnsoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdQr1GFIanC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "cba1eb7c-225d-4246-8ddc-56b4fc716b5d"
      },
      "source": [
        "# Personal tools.\n",
        "!pip install git+https://github.com/Ladvien/ladvien_ml.git\n",
        "from ladvien_ml import FeatureModel\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation,\\\n",
        "                                     Input, LeakyReLU, BatchNormalization, ReLU\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.callbacks import History \n",
        "\n",
        "fm = FeatureModel()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Ladvien/ladvien_ml.git\n",
            "  Cloning https://github.com/Ladvien/ladvien_ml.git to /tmp/pip-req-build-3h32wb8y\n",
            "  Running command git clone -q https://github.com/Ladvien/ladvien_ml.git /tmp/pip-req-build-3h32wb8y\n",
            "Requirement already satisfied (use --upgrade to upgrade): ladvien-ml==0.0.1 from git+https://github.com/Ladvien/ladvien_ml.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: ladvien-ml\n",
            "  Building wheel for ladvien-ml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ladvien-ml: filename=ladvien_ml-0.0.1-cp36-none-any.whl size=10658 sha256=55f6dbf394f8e72c4554eb92c95f487165163dbb30a13327739d7a091f062cbe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fukr9a5a/wheels/c3/84/cb/159d16e33d8e5df3db4d1eae4b5066b58b86cd5131cd82f985\n",
            "Successfully built ladvien-ml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBUUNx6kazDk",
        "colab_type": "text"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9k1Q-OzauH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(input, e_activation, e_batchnorm, dropout = 0.1):\n",
        "  \n",
        "  # Input layer\n",
        "  E = input\n",
        "  \n",
        "  # First Hidden Layer\n",
        "  E = Dense(int(input.shape[1].value * 0.75), activation = e_activation)(E)\n",
        "  if e_batchnorm:\n",
        "    E = BatchNormalization()(E)\n",
        "  E = Dropout(d_dropout)(E)\n",
        "\n",
        "  # Second Hidden Layer\n",
        "  E = Dense(int(input.shape[1].value * 0.50), activation = e_activation)(E)\n",
        "  if e_batchnorm:\n",
        "    E = BatchNormalization()(E)\n",
        "  E = Dropout(d_dropout)(E)\n",
        "\n",
        "  # # Third Hidden Layer\n",
        "  E = Dense(int(input.shape[1].value * 0.25), activation = e_activation)(E)\n",
        "  if e_batchnorm:\n",
        "    E = BatchNormalization()(E)\n",
        "  E = Dropout(d_dropout)(E)\n",
        "\n",
        "  E._name = 'encoder'\n",
        "\n",
        "  return E"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpsIDcgep7C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(encoder, output_shape, optimizer, last_activation, activation, batch_norm, dropout = 0.1):\n",
        "  \n",
        "  input_shape = encoder.shape[1].value\n",
        "\n",
        "  # First Hidden Layer\n",
        "  D = Dense(int(input_shape / 0.75), activation = activation)(encoder)\n",
        "  if batch_norm:\n",
        "    D = BatchNormalization()(D)\n",
        "  D = Dropout(dropout)(D)\n",
        "\n",
        "  # Second Hidden Layer\n",
        "  D = Dense(int(input_shape / 0.50), activation = activation)(D)\n",
        "  if batch_norm:\n",
        "    D = BatchNormalization()(D)\n",
        "  D = Dropout(dropout)(D)\n",
        "\n",
        "  # # Third Hidden Layer\n",
        "  D = Dense(output_shape, activation = activation)(D)\n",
        "  if batch_norm:\n",
        "    D = BatchNormalization()(D)\n",
        "  D = Dropout(dropout)(D)\n",
        "\n",
        "  D._name = 'decoder'\n",
        "\n",
        "  return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ-DQljccNy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "84bf98bb-519d-4809-e338-e823278d0d9f"
      },
      "source": [
        "# Input shape will be the number of possible characters times \n",
        "# the maximum name length allowed.\n",
        "vectorized_name_length = df.shape[1]\n",
        "\n",
        "# Select optimizer.\n",
        "optimizer = fm.select_optimizer(optimizer_name, learning_rate)\n",
        "\n",
        "# Select activation function for hidden layers.\n",
        "if e_h_activation == 'relu':\n",
        "  e_activation = ReLU()\n",
        "elif e_h_activation == 'lrelu':\n",
        "  e_activation = LeakyReLU()\n",
        "\n",
        "if d_h_activation == 'relu':\n",
        "  d_activation = ReLU()\n",
        "elif d_h_activation == 'lrelu':\n",
        "  d_activation = LeakyReLU()\n",
        "\n",
        "I = Input(shape=(inputs))\n",
        "\n",
        "E = encoder(I, e_activation, e_batchnorm, dropout = e_dropout)\n",
        "D = decoder(E, inputs, optimizer, activation, d_activation, e_batchnorm, dropout = e_dropout)\n",
        "\n",
        "autoencoder = Model(I, D)\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 270)]             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 202)               54742     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 202)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 135)               27405     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 135)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 67)                9112      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 67)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 89)                6052      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 89)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 134)               12060     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 134)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 270)               36450     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 270)               0         \n",
            "=================================================================\n",
            "Total params: 145,821\n",
            "Trainable params: 145,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2xKTDjhw4eF",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvbBt1vew8wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomize inputs.\n",
        "df = df.sample(df.shape[0])\n",
        "\n",
        "# Make sure no odd nans.\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "# Drop the 'name' and 'real' columns.\n",
        "X = df.iloc[:,1:]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, X, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TndZjHenw-BZ",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNYzWMYVduSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f169524-e574-4274-e0f7-1ee40e6ac4c5"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 74310 samples, validate on 18578 samples\n",
            "Epoch 1/100\n",
            "74310/74310 [==============================] - 8s 104us/sample - loss: 0.2933 - acc: 0.9630 - val_loss: 0.1591 - val_acc: 0.9630\n",
            "Epoch 2/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2371 - acc: 0.9638 - val_loss: 0.1358 - val_acc: 0.9630\n",
            "Epoch 3/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2256 - acc: 0.9676 - val_loss: 0.1281 - val_acc: 0.9633\n",
            "Epoch 4/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.2197 - acc: 0.9702 - val_loss: 0.1218 - val_acc: 0.9683\n",
            "Epoch 5/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.2154 - acc: 0.9709 - val_loss: 0.1171 - val_acc: 0.9706\n",
            "Epoch 6/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2117 - acc: 0.9712 - val_loss: 0.1133 - val_acc: 0.9717\n",
            "Epoch 7/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.2093 - acc: 0.9715 - val_loss: 0.1105 - val_acc: 0.9724\n",
            "Epoch 8/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2069 - acc: 0.9717 - val_loss: 0.1085 - val_acc: 0.9729\n",
            "Epoch 9/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2052 - acc: 0.9718 - val_loss: 0.1065 - val_acc: 0.9733\n",
            "Epoch 10/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.2043 - acc: 0.9719 - val_loss: 0.1049 - val_acc: 0.9735\n",
            "Epoch 11/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.2033 - acc: 0.9720 - val_loss: 0.1036 - val_acc: 0.9736\n",
            "Epoch 12/100\n",
            "74310/74310 [==============================] - 7s 101us/sample - loss: 0.2019 - acc: 0.9722 - val_loss: 0.1020 - val_acc: 0.9738\n",
            "Epoch 13/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.2012 - acc: 0.9722 - val_loss: 0.1009 - val_acc: 0.9740\n",
            "Epoch 14/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.2001 - acc: 0.9723 - val_loss: 0.0999 - val_acc: 0.9739\n",
            "Epoch 15/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1994 - acc: 0.9723 - val_loss: 0.0989 - val_acc: 0.9741\n",
            "Epoch 16/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1989 - acc: 0.9724 - val_loss: 0.0980 - val_acc: 0.9742\n",
            "Epoch 17/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.1987 - acc: 0.9725 - val_loss: 0.0970 - val_acc: 0.9743\n",
            "Epoch 18/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1976 - acc: 0.9726 - val_loss: 0.0963 - val_acc: 0.9744\n",
            "Epoch 19/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1975 - acc: 0.9726 - val_loss: 0.0954 - val_acc: 0.9745\n",
            "Epoch 20/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.1974 - acc: 0.9727 - val_loss: 0.0945 - val_acc: 0.9746\n",
            "Epoch 21/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1965 - acc: 0.9727 - val_loss: 0.0941 - val_acc: 0.9746\n",
            "Epoch 22/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1962 - acc: 0.9727 - val_loss: 0.0940 - val_acc: 0.9746\n",
            "Epoch 23/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.1961 - acc: 0.9728 - val_loss: 0.0935 - val_acc: 0.9746\n",
            "Epoch 24/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.1958 - acc: 0.9728 - val_loss: 0.0930 - val_acc: 0.9747\n",
            "Epoch 25/100\n",
            "74310/74310 [==============================] - 8s 104us/sample - loss: 0.1959 - acc: 0.9728 - val_loss: 0.0922 - val_acc: 0.9748\n",
            "Epoch 26/100\n",
            "74310/74310 [==============================] - 8s 104us/sample - loss: 0.1953 - acc: 0.9729 - val_loss: 0.0925 - val_acc: 0.9745\n",
            "Epoch 27/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.1949 - acc: 0.9729 - val_loss: 0.0918 - val_acc: 0.9747\n",
            "Epoch 28/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1948 - acc: 0.9730 - val_loss: 0.0915 - val_acc: 0.9747\n",
            "Epoch 29/100\n",
            "74310/74310 [==============================] - 7s 100us/sample - loss: 0.1946 - acc: 0.9730 - val_loss: 0.0914 - val_acc: 0.9747\n",
            "Epoch 30/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1942 - acc: 0.9730 - val_loss: 0.0907 - val_acc: 0.9749\n",
            "Epoch 31/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.1944 - acc: 0.9731 - val_loss: 0.0906 - val_acc: 0.9747\n",
            "Epoch 32/100\n",
            "74310/74310 [==============================] - 7s 98us/sample - loss: 0.1940 - acc: 0.9731 - val_loss: 0.0902 - val_acc: 0.9748\n",
            "Epoch 33/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1940 - acc: 0.9731 - val_loss: 0.0900 - val_acc: 0.9748\n",
            "Epoch 34/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1936 - acc: 0.9732 - val_loss: 0.0899 - val_acc: 0.9749\n",
            "Epoch 35/100\n",
            "74310/74310 [==============================] - 7s 97us/sample - loss: 0.1933 - acc: 0.9732 - val_loss: 0.0897 - val_acc: 0.9750\n",
            "Epoch 36/100\n",
            "74310/74310 [==============================] - 7s 99us/sample - loss: 0.1934 - acc: 0.9732 - val_loss: 0.0896 - val_acc: 0.9749\n",
            "Epoch 37/100\n",
            "62720/74310 [========================>.....] - ETA: 1s - loss: 0.1932 - acc: 0.9732"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J_02aMWjrKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ2XMSIOwpUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}